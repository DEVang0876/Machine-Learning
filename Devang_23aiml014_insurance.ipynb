{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "832c35d8",
   "metadata": {},
   "source": [
    "# Health Insurance Premium Prediction Project\n",
    "\n",
    "## Project Overview\n",
    "This project aims to predict health insurance premiums using Ordinary Least Squares (OLS) regression with comprehensive feature engineering and selection techniques including:\n",
    "- Variance Inflation Factor (VIF) analysis for multicollinearity detection\n",
    "- Correlation analysis for feature selection\n",
    "- Feature engineering to improve model performance\n",
    "\n",
    "## Dataset\n",
    "The dataset contains health insurance information with features like age, sex, BMI, children, smoker status, region, and insurance charges.\n",
    "\n",
    "## Methodology\n",
    "1. **Data Exploration and Preprocessing**\n",
    "2. **Feature Engineering**\n",
    "3. **Feature Selection using Correlation and VIF**\n",
    "4. **OLS Model Implementation**\n",
    "5. **Model Evaluation and Diagnostics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f18c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, visualization, and modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6efc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the insurance dataset\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b11966",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80134833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicate records\n",
    "print(f\"\\nNumber of duplicate records: {df.duplicated().sum()}\")\n",
    "\n",
    "# Display unique values for categorical columns\n",
    "categorical_cols = ['sex', 'smoker', 'region']\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nUnique values in {col}: {df[col].unique()}\")\n",
    "    print(f\"Value counts for {col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7899533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for data distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Distribution of numerical variables\n",
    "numerical_cols = ['age', 'bmi', 'children', 'charges']\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    row = i // 2\n",
    "    col_idx = i % 2\n",
    "    axes[row, col_idx].hist(df[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[row, col_idx].set_title(f'Distribution of {col}')\n",
    "    axes[row, col_idx].set_xlabel(col)\n",
    "    axes[row, col_idx].set_ylabel('Frequency')\n",
    "\n",
    "# Bar plots for categorical variables\n",
    "axes[0, 2].bar(df['sex'].value_counts().index, df['sex'].value_counts().values)\n",
    "axes[0, 2].set_title('Distribution of Sex')\n",
    "axes[0, 2].set_xlabel('Sex')\n",
    "axes[0, 2].set_ylabel('Count')\n",
    "\n",
    "axes[1, 2].bar(df['smoker'].value_counts().index, df['smoker'].value_counts().values)\n",
    "axes[1, 2].set_title('Distribution of Smoker')\n",
    "axes[1, 2].set_xlabel('Smoker')\n",
    "axes[1, 2].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the target variable (charges) in more detail\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df['charges'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Insurance Charges')\n",
    "plt.xlabel('Charges')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(np.log(df['charges']), bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Log(Charges)')\n",
    "plt.xlabel('Log(Charges)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot(df['charges'])\n",
    "plt.title('Boxplot of Insurance Charges')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary of charges\n",
    "print(\"Statistical Summary of Insurance Charges:\")\n",
    "print(f\"Mean: ${df['charges'].mean():.2f}\")\n",
    "print(f\"Median: ${df['charges'].median():.2f}\")\n",
    "print(f\"Standard Deviation: ${df['charges'].std():.2f}\")\n",
    "print(f\"Minimum: ${df['charges'].min():.2f}\")\n",
    "print(f\"Maximum: ${df['charges'].max():.2f}\")\n",
    "print(f\"Skewness: {df['charges'].skew():.2f}\")\n",
    "print(f\"Kurtosis: {df['charges'].kurtosis():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a299a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationships between features and target variable\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Age vs Charges\n",
    "axes[0, 0].scatter(df['age'], df['charges'], alpha=0.6)\n",
    "axes[0, 0].set_title('Age vs Insurance Charges')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Charges')\n",
    "\n",
    "# BMI vs Charges\n",
    "axes[0, 1].scatter(df['bmi'], df['charges'], alpha=0.6)\n",
    "axes[0, 1].set_title('BMI vs Insurance Charges')\n",
    "axes[0, 1].set_xlabel('BMI')\n",
    "axes[0, 1].set_ylabel('Charges')\n",
    "\n",
    "# Children vs Charges\n",
    "axes[0, 2].boxplot([df[df['children'] == i]['charges'].values for i in range(6)], \n",
    "                   labels=range(6))\n",
    "axes[0, 2].set_title('Children vs Insurance Charges')\n",
    "axes[0, 2].set_xlabel('Number of Children')\n",
    "axes[0, 2].set_ylabel('Charges')\n",
    "\n",
    "# Sex vs Charges\n",
    "sns.boxplot(data=df, x='sex', y='charges', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Sex vs Insurance Charges')\n",
    "\n",
    "# Smoker vs Charges\n",
    "sns.boxplot(data=df, x='smoker', y='charges', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Smoker vs Insurance Charges')\n",
    "\n",
    "# Region vs Charges\n",
    "sns.boxplot(data=df, x='region', y='charges', ax=axes[1, 2])\n",
    "axes[1, 2].set_title('Region vs Insurance Charges')\n",
    "axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf03cd8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset for feature engineering\n",
    "df_engineered = df.copy()\n",
    "\n",
    "# 1. Create BMI categories\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif bmi < 25:\n",
    "        return 'Normal'\n",
    "    elif bmi < 30:\n",
    "        return 'Overweight'\n",
    "    else:\n",
    "        return 'Obese'\n",
    "\n",
    "df_engineered['bmi_category'] = df_engineered['bmi'].apply(categorize_bmi)\n",
    "\n",
    "# 2. Create age groups\n",
    "def categorize_age(age):\n",
    "    if age < 25:\n",
    "        return 'Young'\n",
    "    elif age < 35:\n",
    "        return 'Young Adult'\n",
    "    elif age < 50:\n",
    "        return 'Middle Age'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "df_engineered['age_group'] = df_engineered['age'].apply(categorize_age)\n",
    "\n",
    "# 3. Create interaction features\n",
    "df_engineered['age_bmi_interaction'] = df_engineered['age'] * df_engineered['bmi']\n",
    "df_engineered['smoker_age_interaction'] = df_engineered['age'] * (df_engineered['smoker'] == 'yes').astype(int)\n",
    "df_engineered['smoker_bmi_interaction'] = df_engineered['bmi'] * (df_engineered['smoker'] == 'yes').astype(int)\n",
    "\n",
    "# 4. Create polynomial features\n",
    "df_engineered['age_squared'] = df_engineered['age'] ** 2\n",
    "df_engineered['bmi_squared'] = df_engineered['bmi'] ** 2\n",
    "\n",
    "# 5. Create binary features for high-risk categories\n",
    "df_engineered['high_bmi'] = (df_engineered['bmi'] >= 30).astype(int)\n",
    "df_engineered['senior_citizen'] = (df_engineered['age'] >= 50).astype(int)\n",
    "\n",
    "print(\"New features created:\")\n",
    "new_features = ['bmi_category', 'age_group', 'age_bmi_interaction', 'smoker_age_interaction', \n",
    "                'smoker_bmi_interaction', 'age_squared', 'bmi_squared', 'high_bmi', 'senior_citizen']\n",
    "for feature in new_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "print(f\"\\nDataset shape after feature engineering: {df_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d04e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using Label Encoding and One-Hot Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encode binary categorical variables\n",
    "le_sex = LabelEncoder()\n",
    "le_smoker = LabelEncoder()\n",
    "\n",
    "df_engineered['sex_encoded'] = le_sex.fit_transform(df_engineered['sex'])\n",
    "df_engineered['smoker_encoded'] = le_smoker.fit_transform(df_engineered['smoker'])\n",
    "\n",
    "# One-hot encode multi-class categorical variables\n",
    "region_dummies = pd.get_dummies(df_engineered['region'], prefix='region')\n",
    "bmi_category_dummies = pd.get_dummies(df_engineered['bmi_category'], prefix='bmi_cat')\n",
    "age_group_dummies = pd.get_dummies(df_engineered['age_group'], prefix='age_grp')\n",
    "\n",
    "# Combine all features\n",
    "df_final = pd.concat([df_engineered, region_dummies, bmi_category_dummies, age_group_dummies], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "columns_to_drop = ['sex', 'smoker', 'region', 'bmi_category', 'age_group']\n",
    "df_final = df_final.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"Categorical encoding completed!\")\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "print(\"\\nFinal features:\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e502a9",
   "metadata": {},
   "source": [
    "## Feature Selection using Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d498854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df_final.corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.5}, mask=mask)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated features (correlation > 0.8 or < -0.8)\n",
    "def find_high_correlation_pairs(corr_matrix, threshold=0.8):\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "    return high_corr_pairs\n",
    "\n",
    "high_corr_pairs = find_high_correlation_pairs(correlation_matrix, threshold=0.8)\n",
    "print(\"Highly correlated feature pairs (|correlation| > 0.8):\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"{pair[0]} - {pair[1]}: {pair[2]:.3f}\")\n",
    "\n",
    "# Correlation with target variable\n",
    "target_correlation = correlation_matrix['charges'].sort_values(key=abs, ascending=False)\n",
    "print(\"\\nCorrelation with target variable (charges):\")\n",
    "print(target_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82397c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features based on correlation analysis\n",
    "# We'll remove one feature from each highly correlated pair, keeping the one more correlated with target\n",
    "\n",
    "features_to_remove = set()\n",
    "\n",
    "# Remove features with very low correlation with target (|correlation| < 0.05)\n",
    "low_correlation_features = target_correlation[abs(target_correlation) < 0.05].index.tolist()\n",
    "if 'charges' in low_correlation_features:\n",
    "    low_correlation_features.remove('charges')\n",
    "\n",
    "print(\"Features with low correlation to target (|correlation| < 0.05):\")\n",
    "print(low_correlation_features)\n",
    "\n",
    "# For highly correlated pairs, remove the one with lower target correlation\n",
    "for pair in high_corr_pairs:\n",
    "    feature1, feature2 = pair[0], pair[1]\n",
    "    if feature1 != 'charges' and feature2 != 'charges':\n",
    "        corr1 = abs(target_correlation[feature1])\n",
    "        corr2 = abs(target_correlation[feature2])\n",
    "        if corr1 < corr2:\n",
    "            features_to_remove.add(feature1)\n",
    "        else:\n",
    "            features_to_remove.add(feature2)\n",
    "\n",
    "# Combine all features to remove\n",
    "features_to_remove.update(low_correlation_features)\n",
    "features_to_remove = list(features_to_remove)\n",
    "\n",
    "print(f\"\\nFeatures to remove based on correlation analysis: {features_to_remove}\")\n",
    "\n",
    "# Create dataset after correlation-based feature removal\n",
    "df_corr_selected = df_final.drop(columns=features_to_remove)\n",
    "print(f\"\\nDataset shape after correlation-based selection: {df_corr_selected.shape}\")\n",
    "print(\"Remaining features:\")\n",
    "print([col for col in df_corr_selected.columns if col != 'charges'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
